
<!DOCTYPE html>
<html lang="en">
        <head>
                <title>COVID-19 CT segmentation demo</title>
                <!--Automatically generated by pyclientsideml. https://github.com/pbizopoulos/pyclientsideml-->
                <meta charset="UTF-8">
                <link href="data:" rel="icon">
                <style>
                    #divInputControl{
                            border-style: groove;
                            }

                    #divInput{
                            border-style: groove;
                            }

                    #divOutput{
                            border-style: groove;
                            }

                    #divInput:hover{
                            border-style: solid;
                            }
                    </style>
                <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
                
        </head>
        <body>
                <div id="divInputControl" style="width:256px;height:256px;position:fixed;top:0px;left:0px;">
                        <div>NOT FOR MEDICAL USE. Choose a lung CT image (.jpg,.png,.gif) and segment COVID-19 lesions using a DNN.</div>
                        <div>
                                <a href=https://github.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct>[url]</a>
                        </div>
                        <div>
                                
                                <input accept="image/*" onchange="imageLoadView();" type="file">
                                
                        </div>
                        <div>
                                <select id="selectModel" onchange="loadModel(predictView);" style="width:100%;">
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.FPN.mobilenet_v2.imagenet/model.json">lesion-segmentation-a.FPN.mobilenet_v2.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.FPN.resnet18.imagenet/model.json">lesion-segmentation-a.FPN.resnet18.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.FPN.vgg11.imagenet/model.json">lesion-segmentation-a.FPN.vgg11.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.FPN.vgg13.imagenet/model.json">lesion-segmentation-a.FPN.vgg13.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.Linknet.mobilenet_v2.imagenet/model.json">lesion-segmentation-a.Linknet.mobilenet_v2.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.Linknet.resnet18.imagenet/model.json">lesion-segmentation-a.Linknet.resnet18.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.Linknet.vgg11.imagenet/model.json">lesion-segmentation-a.Linknet.vgg11.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.Linknet.vgg13.imagenet/model.json">lesion-segmentation-a.Linknet.vgg13.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lesion-segmentation-a.Unet.mobilenet_v2.imagenet/model.json">lesion-segmentation-a.Unet.mobilenet_v2.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.FPN.mobilenet_v2.imagenet/model.json">lung-segmentation.FPN.mobilenet_v2.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.FPN.resnet18.imagenet/model.json">lung-segmentation.FPN.resnet18.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.FPN.vgg11.imagenet/model.json">lung-segmentation.FPN.vgg11.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.FPN.vgg13.imagenet/model.json">lung-segmentation.FPN.vgg13.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.Linknet.mobilenet_v2.imagenet/model.json">lung-segmentation.Linknet.mobilenet_v2.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.Linknet.resnet18.imagenet/model.json">lung-segmentation.Linknet.resnet18.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.Linknet.vgg11.imagenet/model.json">lung-segmentation.Linknet.vgg11.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.Linknet.vgg13.imagenet/model.json">lung-segmentation.Linknet.vgg13.imagenet</option>
                                     
                                     <option  value="https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-inct-tfjs/master/lung-segmentation.Unet.mobilenet_v2.imagenet/model.json">lung-segmentation.Unet.mobilenet_v2.imagenet</option>
                                     
                                </select>
                        </div>
                        <div style="position:absolute;bottom:0;">Made with 
                                <a href="https://github.com/pbizopoulos/pyclientsideml">pyclientsideml</a>.
                        </div>
                </div>
                <div id="divInput" style="width:256px;height:256px;position:fixed;top:0px;left:256px;">
                        
                        <canvas height="256" id="canvasImageInput" width="256"></canvas>
                        
                </div>
                <div id="divOutput" style="width:256px;height:256px;position:fixed;top:0px;left:512px;">
                        
                        <canvas height="256" id="canvasImageOutput" width="256"></canvas>
                        <canvas height="256" id="canvasMaskOutput" style="position:absolute;top:0px;left:0px;" width="256"></canvas>
                        
                </div>
                <script>
                const canvasWidth = 256;
                const canvasHeight = 256;
                const inputFilename = "https://raw.githubusercontent.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct/master/docs/example-image-1.jpg";
                
                    const canvasImageInput = document.getElementById("canvasImageInput");
                    const contextImageInput = canvasImageInput.getContext("2d");
                    
                    const canvasImageOutput = document.getElementById("canvasImageOutput");
                    const contextImageOutput = canvasImageOutput.getContext("2d");
                    const canvasMaskOutput = document.getElementById("canvasMaskOutput");
                    const contextMaskOutput = canvasMaskOutput.getContext("2d");
                    

                    function getCursorPosition(canvas, event) {
                            const rect = canvas.getBoundingClientRect()
                            const x = event.clientX - rect.left
                            const y = event.clientY - rect.top
                            return [x, y];
                            }

                    function imageLoadView() {
                            const files = event.currentTarget.files;
                            if (files[0]) {
                                imageFileReader.readAsDataURL(files[0]);
                                }
                            }

                    canvasImageInput.onclick = function(event) {

                            contextImageInput.clearRect(0, 0, canvasWidth, canvasHeight);
                            contextImageInput.save();
                            
                            contextImageOutput.clearRect(0, 0, canvasWidth, canvasHeight);
                            contextImageOutput.save();
                            
                            const [x, y] = getCursorPosition(canvasImageInput, event);
                            let isUpper = y < canvasHeight/3;
                            let isLower = y > 2*canvasHeight/3;
                            let isLeft = x < canvasWidth/3;
                            let isRight = x > 2*canvasWidth/3;
                            let isLeftMiddle = isLeft && !(isUpper || isLower);
                            let isRightMiddle = isRight && !(isUpper || isLower);
                            let isUpperLeft = isUpper && isLeft;
                            let isUpperMiddle = isUpper && !(isLeft || isRight);
                            let isUpperRight = isUpper && isRight;
                            let isLowerLeft = isLower && isLeft;
                            let isLowerMiddle = isLower && !(isLeft || isRight);
                            let isLowerRight = isLower && isRight;
                            let rotationDegree;
                            if (isUpperMiddle) {
                                rotationDegree = 0;
                                }
                            else if (isUpperRight) {
                                rotationDegree = 45;
                                }
                            else if (isRightMiddle) {
                                rotationDegree = 90;
                                }
                            else if (isLowerRight) {
                                rotationDegree = 135;
                                }
                            else if (isLowerMiddle) {
                                rotationDegree = 180;
                                }
                            else if (isLowerLeft) {
                                rotationDegree = 225;
                                }
                            else if (isLeftMiddle) {
                                rotationDegree = 270;
                                }
                            else if (isUpperLeft) {
                                rotationDegree = 315;
                                }
                            else {
                                rotationDegree = 360;
                                }
                            contextImageInput.translate(canvasWidth/2, canvasHeight/2);
                            contextImageInput.rotate(rotationDegree*Math.PI/180);
                    contextImageInput.drawImage(imageInput, 0, 0, imageInput.width, imageInput.height, -canvasWidth/2, -canvasHeight/2, canvasWidth, canvasHeight);
                            contextImageInput.restore();
                            
                    contextImageOutput.translate(canvasWidth/2, canvasHeight/2);
                            contextImageOutput.rotate(rotationDegree*Math.PI/180);
                            contextImageOutput.drawImage(imageInput, 0, 0, imageInput.width, imageInput.height, -canvasWidth/2, -canvasHeight/2, canvasWidth, canvasHeight);
                            contextImageOutput.restore();
                            
                            predictView();
                            }

                    let imageInput = new Image();
                    const imageFileReader = new FileReader();
                    imageFileReader.onload = () => {
                            imageInput.src = imageFileReader.result;
                            };

                    imageInput.crossOrigin = 'anonymous';
                    imageInput.src = inputFilename;
                    imageInput.onload = () => {
                            contextImageInput.clearRect(0, 0, canvasWidth, canvasHeight);
                            contextImageInput.drawImage(imageInput, 0, 0, imageInput.width, imageInput.height, 0, 0, canvasWidth, canvasHeight);
                            
                            contextImageOutput.clearRect(0, 0, canvasWidth, canvasHeight);
                            contextImageOutput.drawImage(imageInput, 0, 0, imageInput.width, imageInput.height, 0, 0, canvasWidth, canvasHeight);
                            
                            predictView();
                            };

                
                

                    function predictView(){
                            if (model === undefined) {
                                return;
                                }
                            tf.tidy(() => {
                                let fromPixels = tf.browser.fromPixels(canvasImageInput);
                                originalShape = fromPixels.shape.slice(0, 2);
                                fromPixels = tf.image.resizeBilinear(fromPixels, [model.inputs[0].shape[2], model.inputs[0].shape[3]]);
                                let pixels = fromPixels.slice([0, 0, 2]).squeeze(-1).expandDims(0).expandDims(0);
                                pixels = pixels.mul(0.011764705882352941);
                                pixels = pixels.sub(1.5);
                                const mask = model.predict(pixels);
                                let maskToPixels = mask.squeeze(0).squeeze(0);
                                const alphaTensor = tf.tensor([0.3]);
                                const alphaChannel = alphaTensor.where(maskToPixels.greaterEqual(0.5), 0);
                                maskToPixels = tf.stack([maskToPixels, tf.zerosLike(maskToPixels), tf.zerosLike(maskToPixels), alphaChannel], -1);
                                maskToPixels = tf.image.resizeBilinear(maskToPixels, originalShape);
                                contextMaskOutput.clearRect(0, 0, canvasWidth, canvasHeight);
                                tf.browser.toPixels(maskToPixels, canvasMaskOutput);
                                });
                            }

                    

                    function disableUI(argument) {
                            const nodes = document.getElementById('divInputControl').getElementsByTagName('*');
                            for(let i = 0; i < nodes.length; i++){
                                nodes[i].disabled = argument;
                                }
                            }

                    let model;
                    async function loadModel(predictFunction) {
                            
                            model = await tf.loadGraphModel(selectModel.value, {onProgress: disableUI(true)});
                            
                            predictFunction();
                            disableUI(false);
                            }
                    loadModel(predictView);
                </script>
        </body>
</html>